{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 12:56:15.863640: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression(X, y, random_state=42, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    regression_models = [\n",
    "        ('Lasso', Lasso(alpha=0.1)),\n",
    "        ('RandomForest', RandomForestRegressor(n_estimators=100, random_state=random_state)),\n",
    "        ('XGBoost', XGBRegressor(n_estimators=100, random_state=random_state)),\n",
    "        ('SVR', SVR(kernel='linear')),\n",
    "        ('k-NN', KNeighborsRegressor(n_neighbors=5)),\n",
    "        ('AdaBoost', AdaBoostRegressor(n_estimators=100, random_state=random_state)),\n",
    "        ('ExtraTrees', ExtraTreesRegressor(n_estimators=100, random_state=random_state))\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "    for name, model in regression_models:\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        test_error = mean_squared_error(y_test, y_pred_test)\n",
    "        test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "        results[name] = {\n",
    "            'test_mse': test_error,\n",
    "            'test_r2': test_r2,\n",
    "            'elapsed_time': elapsed_time\n",
    "        }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load and preprocess the datasets\n",
    "def load_and_preprocess_parkinsons():\n",
    "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/telemonitoring/parkinsons_updrs.data'\n",
    "    df = pd.read_csv(url)\n",
    "    df = df.drop(['subject#'], axis=1)\n",
    "    X = df.drop(['motor_UPDRS', 'total_UPDRS'], axis=1).values\n",
    "    y = df['total_UPDRS'].values\n",
    "    return X, y\n",
    "\n",
    "def load_and_preprocess_energy():\n",
    "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx'\n",
    "    df = pd.read_excel(url)\n",
    "    X = df.drop(['Y1', 'Y2'], axis=1).values\n",
    "    y = df['Y1'].values\n",
    "    return X, y\n",
    "\n",
    "# def load_and_preprocess_superconductivity():\n",
    "#     url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00464/superconduct.zip'\n",
    "#     df = pd.read_csv(url, compression='zip')\n",
    "#     X = df.drop(['critical_temp'], axis=1).values\n",
    "#     y = df['critical_temp'].values\n",
    "#     return X, y\n",
    "\n",
    "def load_and_preprocess_superconductivity():\n",
    "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00464/superconduct.zip'\n",
    "    response = requests.get(url)\n",
    "    zf = zipfile.ZipFile(BytesIO(response.content))\n",
    "    df = pd.read_csv(zf.open('train.csv'))\n",
    "    X = df.drop(['critical_temp'], axis=1).values\n",
    "    y = df['critical_temp'].values\n",
    "    return X, y\n",
    "\n",
    "def load_and_preprocess_forest_fires():\n",
    "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv'\n",
    "    df = pd.read_csv(url)\n",
    "    df = pd.get_dummies(df)\n",
    "    X = df.drop(['area'], axis=1).values\n",
    "    y = df['area'].values\n",
    "    return X, y\n",
    "\n",
    "def load_and_preprocess_wine_quality():\n",
    "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "    df = pd.read_csv(url, delimiter=';')\n",
    "    X = df.drop(['quality'], axis=1).values\n",
    "    y = df['quality'].values\n",
    "    return X, y\n",
    "\n",
    "X_parkinsons, y_parkinsons = load_and_preprocess_parkinsons()\n",
    "X_energy, y_energy = load_and_preprocess_energy()\n",
    "X_superconductivity, y_superconductivity = load_and_preprocess_superconductivity()\n",
    "X_forest_fires, y_forest_fires = load_and_preprocess_forest_fires()\n",
    "X_wine_quality, y_wine_quality = load_and_preprocess_wine_quality()\n",
    "\n",
    "# Scale the datasets\n",
    "scaler_parkinsons = StandardScaler().fit(X_parkinsons)\n",
    "scaler_energy = StandardScaler().fit(X_energy)\n",
    "scaler_superconductivity = StandardScaler().fit(X_superconductivity)\n",
    "scaler_forest_fires = StandardScaler().fit(X_forest_fires)\n",
    "scaler_wine_quality = StandardScaler().fit(X_wine_quality)\n",
    "\n",
    "X_parkinsons_scaled = scaler_parkinsons.transform(X_parkinsons)\n",
    "X_energy_scaled = scaler_energy.transform(X_energy)\n",
    "X_superconductivity_scaled = scaler_superconductivity.transform(X_superconductivity)\n",
    "X_forest_fires_scaled = scaler_forest_fires.transform(X_forest_fires)\n",
    "X_wine_quality_scaled = scaler_wine_quality.transform(X_wine_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parkinsons:\n",
      "Lasso: Test MSE: 93.4615, Test R2: 0.1566\n",
      "RandomForest: Test MSE: 2.5748, Test R2: 0.9768\n",
      "XGBoost: Test MSE: 4.8244, Test R2: 0.9565\n",
      "SVR: Test MSE: 96.6305, Test R2: 0.1280\n",
      "k-NN: Test MSE: 39.4418, Test R2: 0.6441\n",
      "AdaBoost: Test MSE: 69.1746, Test R2: 0.3758\n",
      "ExtraTrees: Test MSE: 2.2313, Test R2: 0.9799\n",
      "\n",
      "Energy Efficiency:\n",
      "Lasso: Test MSE: 9.9394, Test R2: 0.9046\n",
      "RandomForest: Test MSE: 0.2444, Test R2: 0.9977\n",
      "XGBoost: Test MSE: 0.1442, Test R2: 0.9986\n",
      "SVR: Test MSE: 9.7768, Test R2: 0.9062\n",
      "k-NN: Test MSE: 5.3575, Test R2: 0.9486\n",
      "AdaBoost: Test MSE: 4.0551, Test R2: 0.9611\n",
      "ExtraTrees: Test MSE: 0.2564, Test R2: 0.9975\n",
      "\n",
      "Superconductivity:\n",
      "Lasso: Test MSE: 328.8063, Test R2: 0.7143\n",
      "RandomForest: Test MSE: 81.4574, Test R2: 0.9292\n",
      "XGBoost: Test MSE: 89.1691, Test R2: 0.9225\n",
      "SVR: Test MSE: 321.2115, Test R2: 0.7209\n",
      "k-NN: Test MSE: 108.9181, Test R2: 0.9054\n",
      "AdaBoost: Test MSE: 408.6658, Test R2: 0.6450\n",
      "ExtraTrees: Test MSE: 78.7690, Test R2: 0.9316\n",
      "\n",
      "Forest Fires:\n",
      "Lasso: Test MSE: 11658.6565, Test R2: 0.0110\n",
      "RandomForest: Test MSE: 12023.1358, Test R2: -0.0200\n",
      "XGBoost: Test MSE: 12906.4237, Test R2: -0.0949\n",
      "SVR: Test MSE: 12126.4118, Test R2: -0.0287\n",
      "k-NN: Test MSE: 11797.5392, Test R2: -0.0008\n",
      "AdaBoost: Test MSE: 11539.5915, Test R2: 0.0211\n",
      "ExtraTrees: Test MSE: 11729.1172, Test R2: 0.0050\n",
      "\n",
      "Wine Quality:\n",
      "Lasso: Test MSE: 0.4389, Test R2: 0.3284\n",
      "RandomForest: Test MSE: 0.3014, Test R2: 0.5389\n",
      "XGBoost: Test MSE: 0.3330, Test R2: 0.4904\n",
      "SVR: Test MSE: 0.3966, Test R2: 0.3931\n",
      "k-NN: Test MSE: 0.4386, Test R2: 0.3288\n",
      "AdaBoost: Test MSE: 0.3854, Test R2: 0.4103\n",
      "ExtraTrees: Test MSE: 0.2926, Test R2: 0.5522\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    'Parkinsons': (X_parkinsons_scaled, y_parkinsons),\n",
    "    'Energy Efficiency': (X_energy_scaled, y_energy),\n",
    "    'Superconductivity': (X_superconductivity_scaled, y_superconductivity),\n",
    "    'Forest Fires': (X_forest_fires_scaled, y_forest_fires),\n",
    "    'Wine Quality': (X_wine_quality_scaled, y_wine_quality)\n",
    "}\n",
    "\n",
    "for dataset_name, (X, y) in datasets.items():\n",
    "    print(f\"\\n{dataset_name}:\")\n",
    "    results = run_regression(X, y)\n",
    "    for model_name, metrics in results.items():\n",
    "        print(f\"{model_name}: Test MSE: {metrics['test_mse']:.4f}, Test R2: {metrics['test_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifiers(X, y, output=None, random_state=42, test_size=0.2, epochs=50, batch_size=16, learning_rate=0.001):\n",
    "    if output == None:\n",
    "        output = len(np.unique(y))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    classifiers = [\n",
    "        ('k-NN', KNeighborsClassifier(n_neighbors=3)),\n",
    "        ('ExtraTrees', ExtraTreesClassifier(n_estimators=100, random_state=random_state)),\n",
    "    ]\n",
    "\n",
    "    nn_setup = {\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for name, classifier in classifiers:\n",
    "        start_time = time.time()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        y_pred_test = classifier.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "        results[name] = {\n",
    "            'mse': mse,\n",
    "            'accuracy': accuracy,\n",
    "            'elapsed_time': elapsed_time\n",
    "        }\n",
    "\n",
    "    # Neural Networks\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(output, activation='softmax'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=nn_setup['learning_rate'])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    y_train_categorical = to_categorical(y_train)\n",
    "    y_test_categorical = to_categorical(y_test)\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train_categorical, epochs=nn_setup['epochs'], batch_size=nn_setup['batch_size'], verbose=0)\n",
    "    elapsed_time_neural_network = time.time() - start_time\n",
    "\n",
    "    y_pred_test_neural_network = np.argmax(model.predict(X_test), axis=1)\n",
    "    mse_neural_network = mean_squared_error(y_test, y_pred_test_neural_network)\n",
    "    accuracy_neural_network = accuracy_score(y_test, y_pred_test_neural_network)\n",
    "\n",
    "    results['neural_network'] = {\n",
    "        'mse': mse_neural_network,\n",
    "        'accuracy': accuracy_neural_network,\n",
    "        'elapsed_time': elapsed_time_neural_network\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
