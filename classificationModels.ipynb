{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required libraries\n",
    "# ! pip install scikit-learn pandas numpy zipfile statistics xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from statistics import mean, stdev\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "digits = load_digits() # dataset containing handwritten digits\n",
    "digits_df = pd.DataFrame(digits.data, columns=digits.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training and test data - 80:20 split\n",
    "x_tr, x_test, y_tr, y_test = train_test_split(digits_df, digits.target, train_size = 0.8, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier for Handwriting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of ET classifier: 0.979 (0.012)\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = ExtraTreesClassifier()\n",
    "\n",
    "# 10-fold cross-validation\n",
    "digits_cv = RepeatedStratifiedKFold(n_splits = 10)\n",
    "cv_scores = cross_val_score(model, x_tr, y_tr, scoring = \"accuracy\", cv = digits_cv)\n",
    "\n",
    "# accuracy using the training data\n",
    "print(\"accuracy of ET classifier: %.3f (%.3f)\" % (mean(cv_scores), stdev(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy for ET: 0.994\n",
      "test MSE for ET: 0.056\n"
     ]
    }
   ],
   "source": [
    "# making predictions on the model using the test data\n",
    "# fitting the model on the training data\n",
    "model.fit(x_tr, y_tr)\n",
    "\n",
    "# making predictions on the test data\n",
    "et_preds = model.predict(x_test)\n",
    "\n",
    "# accuracy\n",
    "print(\"test accuracy for ET: %.3f\" % metrics.accuracy_score(y_test, et_preds))\n",
    "# MSE\n",
    "print(\"test MSE for ET: %.3f\" % metrics.mean_squared_error(y_test, et_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Algorithm For Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of RF classifier: 0.971 (0.014)\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# 10-fold cross-validation\n",
    "digits_cv = RepeatedStratifiedKFold(n_splits = 10)\n",
    "cv_scores = cross_val_score(model, x_tr, y_tr, scoring = \"accuracy\", cv = digits_cv)\n",
    "\n",
    "# accuracy using the training data\n",
    "print(\"accuracy of RF classifier: %.3f (%.3f)\" % (mean(cv_scores), stdev(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy for RF: 0.983\n",
      "test MSE for RF: 0.381\n"
     ]
    }
   ],
   "source": [
    "# fitting the model on the training data\n",
    "model.fit(x_tr, y_tr)\n",
    "\n",
    "# making predictions using the fitted model on the test data\n",
    "rf_preds = model.predict(x_test)\n",
    "\n",
    "# accuracy\n",
    "print(\"test accuracy for RF: %.3f\" % metrics.accuracy_score(y_test, rf_preds))\n",
    "# MSE\n",
    "print(\"test MSE for RF: %.3f\" % metrics.mean_squared_error(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost For Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of XGB classifier: 0.963 (0.016)\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# 10-fold cross-validation\n",
    "digits_cv = RepeatedStratifiedKFold(n_splits = 10)\n",
    "cv_scores = cross_val_score(model, x_tr, y_tr, scoring = \"accuracy\", cv = digits_cv)\n",
    "\n",
    "# accuracy using the training data\n",
    "print(\"accuracy of XGB classifier: %.3f (%.3f)\" % (mean(cv_scores), stdev(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy for XGB: 0.981\n",
      "test MSE for XGB: 0.342\n"
     ]
    }
   ],
   "source": [
    "# fitting the model on the training data\n",
    "model.fit(x_tr, y_tr)\n",
    "\n",
    "# making predictions using the fitted model on the test data\n",
    "xgb_preds = model.predict(x_test)\n",
    "\n",
    "# accuracy\n",
    "print(\"test accuracy for XGB: %.3f\" % metrics.accuracy_score(y_test, xgb_preds))\n",
    "# MSE\n",
    "print(\"test MSE for XGB: %.3f\" % metrics.mean_squared_error(y_test, xgb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of support vector classifier: 0.984 (0.011)\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = SVC(kernel = \"rbf\")\n",
    "\n",
    "# 10-fold cross-validation\n",
    "digits_cv = RepeatedStratifiedKFold(n_splits = 10)\n",
    "cv_scores = cross_val_score(model, x_tr, y_tr, scoring = \"accuracy\", cv = digits_cv)\n",
    "\n",
    "# accuracy using the training data\n",
    "print(\"accuracy of support vector classifier: %.3f (%.3f)\" % (mean(cv_scores), stdev(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy for SVC: 0.997\n",
      "test MSE for SVC: 0.011\n"
     ]
    }
   ],
   "source": [
    "# fitting the model on the training data\n",
    "model.fit(x_tr, y_tr)\n",
    "\n",
    "# making predictions using the fitted model on the test data\n",
    "svc_preds = model.predict(x_test)\n",
    "\n",
    "# accuracy\n",
    "print(\"test accuracy for SVC: %.3f\" % metrics.accuracy_score(y_test, svc_preds))\n",
    "# MSE\n",
    "print(\"test MSE for SVC: %.3f\" % metrics.mean_squared_error(y_test, svc_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of support vector classifier: 0.953 (0.016)\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "# 10-fold cross-validation\n",
    "digits_cv = RepeatedStratifiedKFold(n_splits = 10)\n",
    "cv_scores = cross_val_score(model, x_tr, y_tr, scoring = \"accuracy\", cv = digits_cv)\n",
    "\n",
    "# accuracy using the training data\n",
    "print(\"accuracy of support vector classifier: %.3f (%.3f)\" % (mean(cv_scores), stdev(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy for LDA: 0.953\n",
      "test MSE for LDA: 1.319\n"
     ]
    }
   ],
   "source": [
    "# fitting the model on the training data\n",
    "model.fit(x_tr, y_tr)\n",
    "\n",
    "# making predictions using the fitted model on the test data\n",
    "lda_preds = model.predict(x_test)\n",
    "\n",
    "# accuracy\n",
    "print(\"test accuracy for LDA: %.3f\" % metrics.accuracy_score(y_test, lda_preds))\n",
    "# MSE\n",
    "print(\"test MSE for LDA: %.3f\" % metrics.mean_squared_error(y_test, lda_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of KNN classifier: 0.985 (0.011)\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "# 10-fold cross-validation\n",
    "digits_cv = RepeatedStratifiedKFold(n_splits = 10)\n",
    "cv_scores = cross_val_score(model, x_tr, y_tr, scoring = \"accuracy\", cv = digits_cv)\n",
    "\n",
    "# accuracy using the training data\n",
    "print(\"accuracy of KNN classifier: %.3f (%.3f)\" % (mean(cv_scores), stdev(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy for KNN Classifier: 0.997\n",
      "test MSE for KNN Classifier: 0.025\n"
     ]
    }
   ],
   "source": [
    "# fitting the model on the training data\n",
    "model.fit(x_tr, y_tr)\n",
    "\n",
    "# making predictions using the fitted model on the test data\n",
    "knn_preds = model.predict(x_test)\n",
    "\n",
    "# accuracy\n",
    "print(\"test accuracy for KNN Classifier: %.3f\" % metrics.accuracy_score(y_test, knn_preds))\n",
    "# MSE\n",
    "print(\"test MSE for KNN Classifier: %.3f\" % metrics.mean_squared_error(y_test, knn_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to run all models\n",
    "def run_models(x_tr, y_tr, x_test, y_test, res, dataset: str, n):\n",
    "\n",
    "    ## EXTRA TREES CLASSIFIER\n",
    "    # defining the model\n",
    "    model = ExtraTreesClassifier()\n",
    "    # n-fold cross-validation\n",
    "    digits_cv = RepeatedStratifiedKFold(n_splits = n)\n",
    "    cv_scores = cross_val_score(model, x_tr, y_tr, scoring = \"accuracy\", cv = digits_cv)\n",
    "    # accuracy using the training data\n",
    "    # print(\"accuracy of ET classifier: %.3f (%.3f)\" % (mean(cv_scores), stdev(cv_scores)))\n",
    "    mean_trscore = round(mean(cv_scores), 3)\n",
    "    std_trscore = round(stdev(cv_scores), 3)\n",
    "    # making predictions on the model using the test data\n",
    "    # fitting the model on the training data\n",
    "    model.fit(x_tr, y_tr)\n",
    "    # making predictions on the test data\n",
    "    et_preds = model.predict(x_test)\n",
    "    # accuracy\n",
    "    # print(\"test accuracy for ET: %.3f\" % metrics.accuracy_score(y_test, et_preds))\n",
    "    test_acc = round(metrics.accuracy_score(y_test, et_preds), 3)\n",
    "    # MSE\n",
    "    # print(\"test MSE for ET: %.3f\" % metrics.mean_squared_error(y_test, et_preds))\n",
    "    test_mse = round(metrics.mean_squared_error(y_test, et_preds), 3)\n",
    "    # add results to the dataframe\n",
    "    res.loc['a'] = [dataset, 'ExtraTreesClassifier', mean_trscore, std_trscore, test_acc, test_mse]\n",
    "\n",
    "    ## RANDOM FOREST\n",
    "    # defining the model\n",
    "    model = RandomForestClassifier()\n",
    "    # n-fold cross-validation\n",
    "    digits_cv = RepeatedStratifiedKFold(n_splits = n)\n",
    "    cv_scores = cross_val_score(model, x_tr, y_tr, scoring = \"accuracy\", cv = digits_cv)\n",
    "    # accuracy using the training data\n",
    "    # print(\"accuracy of RF classifier: %.3f (%.3f)\" % (mean(cv_scores), stdev(cv_scores)))\n",
    "    mean_trscore = round(mean(cv_scores), 3)\n",
    "    std_trscore = round(stdev(cv_scores), 3)\n",
    "    # fitting the model on the training data\n",
    "    model.fit(x_tr, y_tr)\n",
    "    # making predictions using the fitted model on the test data\n",
    "    rf_preds = model.predict(x_test)\n",
    "    # accuracy\n",
    "    # print(\"test accuracy for RF: %.3f\" % metrics.accuracy_score(y_test, rf_preds))\n",
    "    test_acc = round(metrics.accuracy_score(y_test, rf_preds), 3)\n",
    "    # MSE\n",
    "    # print(\"test MSE for RF: %.3f\" % metrics.mean_squared_error(y_test, rf_preds))\n",
    "    test_mse = round(metrics.mean_squared_error(y_test, rf_preds), 3)\n",
    "    # add results to the dataframe\n",
    "    res.loc['b'] = [dataset, 'RandomForestClassifier', mean_trscore, std_trscore, test_acc, test_mse]\n",
    "    \n",
    "    ## XGBOOST\n",
    "    # defining the model\n",
    "    model = XGBClassifier()\n",
    "    # n-fold cross-validation\n",
    "    digits_cv = RepeatedStratifiedKFold(n_splits = n)\n",
    "    cv_scores = cross_val_score(model, x_tr, y_tr, scoring = \"accuracy\", cv = digits_cv)\n",
    "    # accuracy using the training data\n",
    "    # print(\"accuracy of XGB classifier: %.3f (%.3f)\" % (mean(cv_scores), stdev(cv_scores)))\n",
    "    mean_trscore = round(mean(cv_scores), 3)\n",
    "    std_trscore = round(stdev(cv_scores), 3)\n",
    "    # fitting the model on the training data\n",
    "    model.fit(x_tr, y_tr)\n",
    "    # making predictions using the fitted model on the test data\n",
    "    xgb_preds = model.predict(x_test)\n",
    "    # accuracy\n",
    "    # print(\"test accuracy for XGB: %.3f\" % metrics.accuracy_score(y_test, xgb_preds))\n",
    "    test_acc = round(metrics.accuracy_score(y_test, xgb_preds), 3)\n",
    "    # MSE\n",
    "    # print(\"test MSE for XGB: %.3f\" % metrics.mean_squared_error(y_test, xgb_preds))\n",
    "    test_mse = round(metrics.mean_squared_error(y_test, xgb_preds), 3)\n",
    "    # add results to the dataframe\n",
    "    res.loc['c'] = [dataset, 'XGBoostClassifier', mean_trscore, std_trscore, test_acc, test_mse]\n",
    "\n",
    "    ## SVC\n",
    "    # defining the model\n",
    "    model = SVC(kernel = \"rbf\")\n",
    "    # n-fold cross-validation\n",
    "    digits_cv = RepeatedStratifiedKFold(n_splits = n)\n",
    "    cv_scores = cross_val_score(model, x_tr, y_tr, scoring = \"accuracy\", cv = digits_cv)\n",
    "    # accuracy using the training data\n",
    "    # print(\"accuracy of support vector classifier: %.3f (%.3f)\" % (mean(cv_scores), stdev(cv_scores)))\n",
    "    mean_trscore = round(mean(cv_scores), 3)\n",
    "    std_trscore = round(stdev(cv_scores), 3)\n",
    "    # fitting the model on the training data\n",
    "    model.fit(x_tr, y_tr)\n",
    "    # making predictions using the fitted model on the test data\n",
    "    svc_preds = model.predict(x_test)\n",
    "    # accuracy\n",
    "    # print(\"test accuracy for SVC: %.3f\" % metrics.accuracy_score(y_test, svc_preds))\n",
    "    test_acc = round(metrics.accuracy_score(y_test, svc_preds), 3)\n",
    "    # MSE\n",
    "    # print(\"test MSE for SVC: %.3f\" % metrics.mean_squared_error(y_test, svc_preds))\n",
    "    test_mse = round(metrics.mean_squared_error(y_test, svc_preds), 3)\n",
    "    # add results to the dataframe\n",
    "    res.loc['d'] = [dataset, 'SupportVectorClassifier', mean_trscore, std_trscore, test_acc, test_mse]\n",
    "\n",
    "    ## LDA\n",
    "    # defining the model\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    # n-fold cross-validation\n",
    "    digits_cv = RepeatedStratifiedKFold(n_splits = n)\n",
    "    cv_scores = cross_val_score(model, x_tr, y_tr, scoring = \"accuracy\", cv = digits_cv)\n",
    "    # accuracy using the training data\n",
    "    # print(\"accuracy of support vector classifier: %.3f (%.3f)\" % (mean(cv_scores), stdev(cv_scores)))\n",
    "    mean_trscore = round(mean(cv_scores), 3)\n",
    "    std_trscore = round(stdev(cv_scores), 3)\n",
    "    # fitting the model on the training data\n",
    "    model.fit(x_tr, y_tr)\n",
    "    # making predictions using the fitted model on the test data\n",
    "    lda_preds = model.predict(x_test)\n",
    "    # accuracy\n",
    "    # print(\"test accuracy for LDA: %.3f\" % metrics.accuracy_score(y_test, lda_preds))\n",
    "    test_acc = round(metrics.accuracy_score(y_test, lda_preds), 3)\n",
    "    # MSE\n",
    "    # print(\"test MSE for LDA: %.3f\" % metrics.mean_squared_error(y_test, lda_preds))\n",
    "    test_mse = round(metrics.mean_squared_error(y_test, lda_preds), 3)\n",
    "    # add results to the dataframe\n",
    "    res.loc['e'] = [dataset, 'LDAClassifier', mean_trscore, std_trscore, test_acc, test_mse]\n",
    "\n",
    "    ## KNN\n",
    "    # defining the model\n",
    "    model = KNeighborsClassifier(n_neighbors = 3)\n",
    "    # n-fold cross-validation\n",
    "    digits_cv = RepeatedStratifiedKFold(n_splits = n)\n",
    "    cv_scores = cross_val_score(model, x_tr, y_tr, scoring = \"accuracy\", cv = digits_cv)\n",
    "    # accuracy using the training data\n",
    "    # print(\"accuracy of KNN classifier: %.3f (%.3f)\" % (mean(cv_scores), stdev(cv_scores)))\n",
    "    mean_trscore = round(mean(cv_scores), 3)\n",
    "    std_trscore = round(stdev(cv_scores), 3)\n",
    "    # fitting the model on the training data\n",
    "    model.fit(x_tr, y_tr)\n",
    "    # making predictions using the fitted model on the test data\n",
    "    knn_preds = model.predict(x_test)\n",
    "    # accuracy\n",
    "    # print(\"test accuracy for KNN Classifier: %.3f\" % metrics.accuracy_score(y_test, knn_preds))\n",
    "    test_acc = round(metrics.accuracy_score(y_test, knn_preds), 3)\n",
    "    # MSE\n",
    "    # print(\"test MSE for KNN Classifier: %.3f\" % metrics.mean_squared_error(y_test, knn_preds))\n",
    "    test_mse = round(metrics.mean_squared_error(y_test, knn_preds), 3)\n",
    "    # add results to the dataframe\n",
    "    res.loc['f'] = [dataset, 'KNNClassifier', mean_trscore, std_trscore, test_acc, test_mse]\n",
    "\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "data = load_digits() # dataset containing handwritten digits\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# splitting the data into training and test data - 80:20 split\n",
    "x_tr, x_test, y_tr, y_test = train_test_split(df, data.target, train_size = 0.8, shuffle = True)\n",
    "le = LabelEncoder()\n",
    "y_tr = le.fit_transform(y_tr)\n",
    "\n",
    "res_digits = run_models(x_tr, y_tr, x_test, y_test, pd.DataFrame(columns = ['dataset', 'model', 'train_score', 'train_score_std', 'test_accuracy', 'test_mse']), \"digits\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>train_score_std</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>digits</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>digits</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>digits</td>\n",
       "      <td>XGBoostClassifier</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>digits</td>\n",
       "      <td>SupportVectorClassifier</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>digits</td>\n",
       "      <td>LDAClassifier</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.961</td>\n",
       "      <td>1.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>digits</td>\n",
       "      <td>KNNClassifier</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                    model  train_score  train_score_std   \n",
       "a  digits     ExtraTreesClassifier        0.980            0.008  \\\n",
       "b  digits   RandomForestClassifier        0.971            0.008   \n",
       "c  digits        XGBoostClassifier        0.958            0.011   \n",
       "d  digits  SupportVectorClassifier        0.988            0.005   \n",
       "e  digits            LDAClassifier        0.949            0.011   \n",
       "f  digits            KNNClassifier        0.988            0.006   \n",
       "\n",
       "   test_accuracy  test_mse  \n",
       "a          0.978     0.492  \n",
       "b          0.969     0.442  \n",
       "c          0.978     0.422  \n",
       "d          0.983     0.397  \n",
       "e          0.961     1.058  \n",
       "f          0.978     0.692  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Quality Dataset - Red Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "df = pd.read_csv('winequality-red.csv', sep = ';')\n",
    "y = df['quality']\n",
    "\n",
    "# splitting the data into training and test data - 80:20 split\n",
    "x_tr, x_test, y_tr, y_test = train_test_split(df, y, train_size = 0.8, shuffle = True, stratify = y)\n",
    "le = LabelEncoder()\n",
    "y_tr = le.fit_transform(y_tr)\n",
    "\n",
    "res_wqred = run_models(x_tr, y_tr, x_test, y_test, pd.DataFrame(columns = ['dataset', 'model', 'train_score', 'train_score_std', 'test_accuracy', 'test_mse']), \"wineQualityRed\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>train_score_std</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>digits</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>digits</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>digits</td>\n",
       "      <td>XGBoostClassifier</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>digits</td>\n",
       "      <td>SupportVectorClassifier</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.003</td>\n",
       "      <td>9.362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>digits</td>\n",
       "      <td>LDAClassifier</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.006</td>\n",
       "      <td>9.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>digits</td>\n",
       "      <td>KNNClassifier</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                    model  train_score  train_score_std   \n",
       "a  digits     ExtraTreesClassifier        0.997            0.003  \\\n",
       "b  digits   RandomForestClassifier        0.981            0.004   \n",
       "c  digits        XGBoostClassifier        1.000            0.000   \n",
       "d  digits  SupportVectorClassifier        0.517            0.027   \n",
       "e  digits            LDAClassifier        0.588            0.025   \n",
       "f  digits            KNNClassifier        0.576            0.023   \n",
       "\n",
       "   test_accuracy  test_mse  \n",
       "a          0.000     8.984  \n",
       "b          0.000     8.981  \n",
       "c          0.000     9.000  \n",
       "d          0.003     9.362  \n",
       "e          0.006     9.638  \n",
       "f          0.000    10.003  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_wqred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Quality Dataset - White Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "df = pd.read_csv('winequality-white.csv', sep = ';')\n",
    "y = df['quality']\n",
    "\n",
    "# splitting the data into training and test data - 80:20 split\n",
    "x_tr, x_test, y_tr, y_test = train_test_split(df, y, train_size = 0.8, shuffle = True)\n",
    "le = LabelEncoder()\n",
    "y_tr = le.fit_transform(y_tr)\n",
    "\n",
    "res_wqwhite = run_models(x_tr, y_tr, x_test, y_test, pd.DataFrame(columns = ['dataset', 'model', 'train_score', 'train_score_std', 'test_accuracy', 'test_mse']), \"wineQualityWhite\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>train_score_std</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>digits</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>digits</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>digits</td>\n",
       "      <td>XGBoostClassifier</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>digits</td>\n",
       "      <td>SupportVectorClassifier</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>9.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>digits</td>\n",
       "      <td>LDAClassifier</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.004</td>\n",
       "      <td>9.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>digits</td>\n",
       "      <td>KNNClassifier</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.002</td>\n",
       "      <td>10.019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                    model  train_score  train_score_std   \n",
       "a  digits     ExtraTreesClassifier        0.999            0.001  \\\n",
       "b  digits   RandomForestClassifier        0.995            0.002   \n",
       "c  digits        XGBoostClassifier        0.999            0.000   \n",
       "d  digits  SupportVectorClassifier        0.454            0.005   \n",
       "e  digits            LDAClassifier        0.528            0.015   \n",
       "f  digits            KNNClassifier        0.505            0.014   \n",
       "\n",
       "   test_accuracy  test_mse  \n",
       "a          0.000     9.000  \n",
       "b          0.000     8.984  \n",
       "c          0.000     9.007  \n",
       "d          0.003     9.433  \n",
       "e          0.004     9.988  \n",
       "f          0.002    10.019  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_wqwhite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy Efficiency - Heating Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy Efficiency - Heating Load\n",
    "df = pd.read_excel('ENB2012_data.xlsx')\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df = df.drop('Y2', axis = 1)\n",
    "df.Y1 = df.Y1.round()\n",
    "df = df.astype({'Y1':'int'})\n",
    "y = df['Y1']\n",
    "\n",
    "\n",
    "# splitting the data into training and test data - 80:20 split\n",
    "x_tr, x_test, y_tr, y_test = train_test_split(df, y, train_size = 0.8, shuffle = True)\n",
    "le = LabelEncoder()\n",
    "y_tr = le.fit_transform(y_tr)\n",
    "\n",
    "res_energy_heating = run_models(x_tr, y_tr, x_test, y_test, pd.DataFrame(columns = ['dataset', 'model', 'train_score', 'train_score_std', 'test_accuracy', 'test_mse']), \"energyEfficiencyHeating\", 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
